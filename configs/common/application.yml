# ========================================
# Config Server - 전역 공통 설정
# 모든 마이크로서비스에서 공통으로 사용되는 설정
# 우선순위: 서비스별 설정 > profile별 설정 > 이 공통 설정
# ========================================

spring:
  # ===== Spring Cloud 통합 설정 =====
  cloud:
    # ----- 로드 밸런서 설정 -----
    # Netflix Ribbon 대신 Spring Cloud LoadBalancer 사용
    loadbalancer:
      ribbon:
        enabled: false  # Netflix Ribbon 비활성화, Spring Cloud LoadBalancer 사용

    # ----- 서킷 브레이커 설정 (Resilience4j) -----
    # 장애 전파 방지 및 시스템 안정성 향상을 위한 설정
    circuitbreaker:
      resilience4j:
        enabled: true  # Resilience4j 회로 차단기 활성화
        configs:
          default:  # 모든 서비스에 적용되는 기본 회로 차단기 설정
            slidingWindowType: COUNT_BASED  # 호출 횟수 기반 슬라이딩 윈도우 (TIME_BASED: 시간 기반)
            slidingWindowSize: 5  # 최근 5개의 호출을 기준으로 상태 결정
            minimumNumberOfCalls: 1  # 회로 차단기 작동을 위한 최소 호출 수
            permittedNumberOfCallsInHalfOpenState: 2  # 반개방 상태에서 허용되는 테스트 호출 수
            failureRateThreshold: 50  # 실패율 50% 초과 시 회로 차단 (OPEN 상태로 전환)
            waitDurationInOpenState: 5s  # 회로가 열린 후 반개방 상태로 전환되기까지 대기 시간
            recordExceptions:  # 실패로 간주할 예외 목록
              - java.lang.RuntimeException
              - org.springframework.web.client.HttpServerErrorException

    # ----- Kafka Stream 설정 -----
    # 이벤트 스트리밍 처리를 위한 Kafka Streams 설정
    stream:
      kafka:
        binder:
          # Kafka 브로커 클러스터 주소 (3개의 브로커로 구성된 클러스터)
          brokers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092,localhost:9093,localhost:9094}
          auto-create-topics: true  # 토픽 자동 생성 (개발 환경용, 운영에서는 false 권장)
          replication-factor: 3  # 데이터 복제 계수 (3개 브로커에 각각 복제)
          min-partition-count: 3  # 최소 파티션 수 (병렬 처리 단위)
      bindings:
        # 입력 채널 설정 (메시지 수신용)
        input:
          destination: ${spring.application.name}-input  # 토픽 이름 (서비스명-input)
          group: ${spring.application.name}-group  # 컨슈머 그룹 (서비스명-group)
          consumer:
            concurrency: 3  # 동시 처리 스레드 수
        # 출력 채널 설정 (메시지 발송용)
        output:
          destination: ${spring.application.name}-output  # 토픽 이름 (서비스명-output)
          producer:
            partition-count: 3  # 파티션 수

  # ===== 데이터베이스 설정 (PostgreSQL) =====
  datasource:
    # JDBC URL 설정 (호스트, 포트, 데이터베이스명 환경변수로 구성)
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:default_db}
    username: ${DB_USERNAME:postgres}  # DB 사용자명
    password: ${DB_PASSWORD:postgres}  # DB 비밀번호
    driver-class-name: org.postgresql.Driver  # PostgreSQL JDBC 드라이버

    # ----- HikariCP 커넥션 풀 설정 -----
    hikari:
      connection-timeout: 30000  # 커넥션 획득 대기 시간 (30초)
      maximum-pool-size: 10  # 최대 커넥션 풀 크기
      minimum-idle: 5  # 최소 유휴 커넥션 수
      idle-timeout: 600000  # 유휴 커넥션 유지 시간 (10분)
      max-lifetime: 1800000  # 커넥션 최대 수명 (30분)

  # ===== JPA/Hibernate 설정 =====
  jpa:
    hibernate:
      ddl-auto: create-drop  # 스키마 자동 생성 전략 (개발: create-drop, 운영: validate)
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect  # PostgreSQL 방언 사용
        format_sql: true  # SQL 포맷팅 (가독성 향상)
        default_schema: app  # 기본 스키마명
        jdbc:
          batch_size: 20  # 배치 처리 크기 (성능 최적화)
        order_inserts: true  # INSERT 순서 정렬 (배치 효율 향상)
        order_updates: true  # UPDATE 순서 정렬 (배치 효율 향상)
    show-sql: false  # SQL 로그 출력 (개발: true, 운영: false)

  # ===== Kafka 메시징 설정 =====
  kafka:
    # Kafka 브로커 클러스터 주소
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092,localhost:9093,localhost:9094}

    # ----- Producer(생산자) 설정 -----
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer  # 키 직렬화
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer  # 값 직렬화 (JSON)
      acks: all  # 모든 복제본 확인 (최고 신뢰성)
      retries: 3  # 전송 실패 시 재시도 횟수
      properties:
        enable.idempotence: true  # 멱등성 보장 (중복 방지)
        max.in.flight.requests.per.connection: 5  # 동시 전송 가능한 요청 수

    # ----- Consumer(소비자) 설정 -----
    consumer:
      group-id: ${KAFKA_CONSUMER_GROUP_ID:${spring.application.name}-group}  # 컨슈머 그룹 ID
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer  # 키 역직렬화
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer  # 값 역직렬화 (JSON)
      auto-offset-reset: earliest  # 오프셋 리셋 정책 (처음부터 읽기)
      enable-auto-commit: false  # 수동 커밋 모드 (트랜잭션 보장)
      properties:
        spring.json.trusted.packages: "*"  # 모든 패키지 신뢰 (역직렬화 허용)
        isolation.level: read_committed  # 커밋된 메시지만 읽기 (트랜잭션 지원)

    # ----- Listener 설정 -----
    listener:
      ack-mode: manual  # 수동 승인 모드 (메시지 처리 보장)
      concurrency: 3  # 동시 처리 리스너 수

  # ===== OAuth2 보안 설정 =====
  security:
    oauth2:
      # ----- Resource Server 설정 (JWT 토큰 검증) -----
      resourceserver:
        jwt:
          # JWT 발급자 URI (Keycloak Realm 엔드포인트)
          issuer-uri: ${KEYCLOAK_ISSUER_URI:https://keycloak.code-factory.co.kr/realms/codefactory}

      # ----- OAuth2 Client 설정 -----
      client:
        registration:
          keycloak:
            client-id: ${KEYCLOAK_CLIENT_ID}  # Keycloak 클라이언트 ID
            client-secret: ${KEYCLOAK_CLIENT_SECRET}  # Keycloak 클라이언트 시크릿
            authorization-grant-type: authorization_code  # OAuth2 인증 방식
            redirect-uri: ${KEYCLOAK_REDIRECT_URI:http://localhost:8080/v1/user/authorization/code}  # 인증 후 리다이렉트 URI
            scope:  # 요청할 권한 범위
              - openid  # OpenID Connect 사용
              - profile  # 사용자 프로필 정보
              - email  # 이메일 정보
        provider:
          keycloak:
            issuer-uri: ${KEYCLOAK_ISSUER_URI:https://keycloak.code-factory.co.kr/realms/codefactory}

  # ===== Keycloak Admin 설정 =====
  # Keycloak 서버 관리를 위한 설정
  keycloak:
    server-url: ${KEYCLOAK_SERVER_URL:https://keycloak.code-factory.co.kr}  # Keycloak 서버 URL
    realm: ${KEYCLOAK_REALM:codefactory}  # Realm 이름
    client-id: ${KEYCLOAK_CLIENT_ID}  # 관리용 클라이언트 ID
    client-secret: ${KEYCLOAK_CLIENT_SECRET}  # 관리용 클라이언트 시크릿
    admin-username: ${KEYCLOAK_ADMIN_USERNAME}  # 관리자 계정
    admin-password: ${KEYCLOAK_ADMIN_PASSWORD}  # 관리자 비밀번호

# ===== Actuator 모니터링 설정 =====
# 애플리케이션 상태 모니터링 및 관리를 위한 설정
management:
  endpoints:
    web:
      exposure:
        # 노출할 엔드포인트 목록
        include: health,info,metrics,prometheus,env,configprops,refresh
  endpoint:
    # 헬스체크 엔드포인트 설정
    health:
      show-details: always  # 상세 정보 항상 표시
    # Prometheus 메트릭 엔드포인트
    prometheus:
      enabled: true  # Prometheus 메트릭 수집 활성화
    # 메트릭 엔드포인트
    metrics:
      enabled: true  # 메트릭 수집 활성화
    # 설정 갱신 엔드포인트
    refresh:
      enabled: true  # Config 갱신 엔드포인트 활성화 (/actuator/refresh)

  # ----- 분산 트레이싱 설정 (Zipkin) -----
  tracing:
    sampling:
      probability: ${TRACING_PROBABILITY:1.0}  # 트레이싱 샘플링 비율 (1.0 = 100% 수집)
  zipkin:
    tracing:
      # Zipkin 서버 엔드포인트 (분산 트레이싱 수집)
      endpoint: ${ZIPKIN_BASE_URL:http://localhost:9411}/api/v2/spans

  # ----- 메트릭 수집 설정 -----
  metrics:
    export:
      prometheus:
        enabled: true  # Prometheus 형식으로 메트릭 내보내기
    tags:
      application: ${spring.application.name}  # 메트릭에 애플리케이션 이름 태그 추가

# ===== 로깅 설정 =====
# 애플리케이션 로깅 구성
logging:
  level:
    com.earlyexpress: DEBUG  # 자체 패키지 디버그 레벨
    org.springframework.cloud: INFO  # Spring Cloud 정보 레벨
    org.springframework.kafka: INFO  # Spring Kafka 정보 레벨
    feign: DEBUG  # Feign 클라이언트 디버그 (API 호출 추적)
  pattern:
    # 콘솔 출력 패턴 (시간, 스레드, 레벨, 로거, 메시지)
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    # 파일 출력 패턴 (콘솔과 동일)
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/${spring.application.name}.log  # 로그 파일 경로 (서비스명.log)
    max-size: 10MB  # 로그 파일 최대 크기
    max-history: 30  # 로그 파일 보관 일수

# ===== WebClient 설정 =====
# 비동기 HTTP 클라이언트 설정
webclient:
  timeout:
    connection: ${WEBCLIENT_CONNECTION_TIMEOUT:5000}  # 연결 타임아웃 (5초)
    read: ${WEBCLIENT_READ_TIMEOUT:10000}  # 읽기 타임아웃 (10초)
    write: ${WEBCLIENT_WRITE_TIMEOUT:10000}  # 쓰기 타임아웃 (10초)
  max-memory-size: ${WEBCLIENT_MAX_MEMORY_SIZE:10485760}  # 최대 메모리 크기 (10MB)
  # 커넥션 풀 설정
  connection-provider:
    max-connections: ${WEBCLIENT_MAX_CONNECTIONS:500}  # 최대 연결 수
    max-idle-time: 20s  # 최대 유휴 시간
    max-life-time: 60s  # 연결 최대 수명
    pending-acquire-timeout: 60s  # 연결 획득 대기 시간
    evict-in-background: 120s  # 백그라운드 연결 정리 주기

# ===== Feign Client 설정 =====
# 선언적 REST 클라이언트 설정
feign:
  client:
    config:
      default:  # 모든 Feign 클라이언트 기본 설정
        connectTimeout: 5000  # 연결 타임아웃 (5초)
        readTimeout: 5000  # 읽기 타임아웃 (5초)
        loggerLevel: full  # 로깅 레벨 (NONE, BASIC, HEADERS, FULL)

# ===== Resilience4j 상세 설정 =====
# 장애 내성 패턴 구현을 위한 설정
resilience4j:
  # ----- 재시도 설정 -----
  retry:
    configs:
      default:
        maxAttempts: 3  # 최대 재시도 횟수 (원본 1회 + 재시도 2회)
        waitDuration: 1s  # 재시도 간 대기 시간
        enableExponentialBackoff: true  # 지수 백오프 활성화
        exponentialBackoffMultiplier: 2.0  # 대기 시간 증가율 (1s → 2s → 4s)
        retryExceptions:  # 재시도할 예외 목록
          - java.lang.RuntimeException

  # ----- 벌크헤드 설정 (동시 호출 제한) -----
  bulkhead:
    configs:
      default:
        type: THREADPOOL  # 스레드풀 격리 방식
        coreThreadPoolSize: 5  # 기본 스레드 수
        maxThreadPoolSize: 10  # 최대 스레드 수
        queueCapacity: 50  # 대기 큐 용량

  # ----- 속도 제한 설정 (Rate Limiter) -----
  ratelimiter:
    configs:
      default:
        limitForPeriod: 50  # 주기당 최대 허용 요청 수
        limitRefreshPeriod: 1s  # 제한 갱신 주기
        timeoutDuration: 0ms  # 허가 대기 시간 (0ms: 즉시 거부)
    instances:
      externalService:  # 외부 서비스용 커스텀 설정
        baseConfig: default
        limitForPeriod: 20  # 외부 API는 더 엄격한 제한
        limitRefreshPeriod: 1s